# fakenews-detector

# ğŸ“° Fake News Detector â€” Local Usage Guide

This project is a full **Fake News Detection System** that runs completely on your computer.

It includes:

- `train_full_fake_new.py` â†’ trains ML models  
- `Fake.csv` + `True.csv` â†’ dataset files **kept in the root folder**  
- `artifacts/` â†’ generated models  
- `app.py` â†’ backend API  
- `frontend/` â†’ HTML/CSS/JS user interface  

This guide explains how to use the project from scratch.

---

# ğŸ“ Project Structure

Make sure your folder looks like this:

```
fake-news-detector/
â”‚
â”œâ”€â”€ train_full_fake_new.py
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ Fake.csv
â”œâ”€â”€ True.csv
â”‚
â”œâ”€â”€ artifacts/              â† AUTO-GENERATED after training
â”‚     â”œâ”€â”€ tfidf.joblib
â”‚     â”œâ”€â”€ nb.joblib
â”‚     â”œâ”€â”€ dt.joblib
â”‚     â”œâ”€â”€ rf.joblib
â”‚     â”œâ”€â”€ gb.joblib
â”‚     â””â”€â”€ stack.joblib
â”‚
â””â”€â”€ frontend/
       â”œâ”€â”€ index.html
       â”œâ”€â”€ style.css
       â”œâ”€â”€ script.js
       â””â”€â”€ bg1.png
```

âœ” CSV files are **in the main root**, EXACTLY like you wanted.  
âŒ No separate data folder.  
âŒ No backend folder.  
âŒ Only nice and simple.

---

# ğŸ“¥ 1. Download Dataset (CSV Files)

This project uses the **Fake and Real News Dataset**:

ğŸ”— https://www.kaggle.com/datasets/clmentbisaillon/fake-and-real-news-dataset

Download and extract the dataset.

You will get:

- `Fake.csv`  
- `True.csv`

Place BOTH files directly in the **project root folder**, like this:

```
fake-news-detector/
   Fake.csv
   True.csv
   train_full_fake_new.py
   app.py
   ...
```

NOT in a separate folder.

---

# ğŸ§° 2. Install Requirements

### Open VS Code
- File â†’ Open Folder â†’ select the project folder

### Open Terminal
Terminal â†’ New Terminal

### Create Virtual Environment

#### Windows:
```powershell
python -m venv venv
.\venv\Scripts\activate
```

#### macOS / Linux:
```bash
python3 -m venv venv
source venv/bin/activate
```

### Install dependencies
```bash
pip install -r requirements.txt
```

### Install NLTK data
```bash
python - <<'PY'
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
PY
```

---

# ğŸ¤– 3. TRAIN THE MODEL (IMPORTANT)

Run the training script:

```bash
python train_full_fake_new.py
```

This will:

âœ” Read `Fake.csv` and `True.csv` from the root  
âœ” Clean the text  
âœ” Train multiple ML models  
âœ” Create an `artifacts/` folder  
âœ” Save all `.joblib` files inside it  

After training finishes, you MUST see:

```
artifacts/
   tfidf.joblib
   nb.joblib
   dt.joblib
   rf.joblib
   gb.joblib
   stack.joblib
```

If this folder exists â†’ training succeeded.

---

# ğŸŒ 4. Run Backend (API)

Your backend is:

```
app.py
```

Run it:

```bash
python app.py
```

It starts here:

```
http://127.0.0.1:5000
```

### Test it:

```bash
curl -X POST -H "Content-Type: application/json" \
-d "{\"text\":\"this is a test news article\"}" \
http://127.0.0.1:5000/predict
```

You should receive JSON output.

---

# ğŸ¨ 5. Run Frontend

Your UI is inside:

```
frontend/
   index.html
   style.css
   script.js
   bg1.png
```

### Easiest method:
Open `index.html` in your browser.

OR run a local server:

```bash
cd frontend
python -m http.server 8000
```

Open:

```
http://localhost:8000
```

Paste your news â†’ click **Analyze** â†’ your backend will respond.

Backend **must** be running for the frontend to work.

---


alsooo lastlyyyy install all the libraries from requirements.txt
